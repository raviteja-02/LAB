{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Question</h1>\n",
    "<p>Implement k-nearest neighbours classification using python\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Explanation:</h1>\n",
    "<p>\n",
    "To run this program, you need to install the sklearn module.<br>\n",
    "Open Command prompt and then execute the following command to install sklearn module:<br>\n",
    "pip install scikit-learn<br>\n",
    "-----------------------------------------------<br>\n",
    "In this program, we are going to use the iris dataset. And this dataset is split into a training set (70%) and test set (30%).<br>\n",
    "The iris dataset contains the following features:<br>\n",
    "---> sepal length (cm)<br>\n",
    "---> sepal width (cm)<br>\n",
    "---> petal length (cm)<br>\n",
    "---> petal width (cm)<br>\n",
    "The sample data in the iris dataset format is [5.4 3.4 1.7 0.2], where:<br>\n",
    "5.4 ---> sepal length (cm)<br>\n",
    "3.4 ---> sepal width (cm)<br>\n",
    "1.7 ---> petal length (cm)<br>\n",
    "0.2 ---> petal width (cm)<br>\n",
    "</p>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>LAB</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Data from Iris Dataset\n",
      "******************************\n",
      "[5.8 2.7 3.9 1.2] ===> versicolor\n",
      "The Training dataset length:  105\n",
      "The Testing dataset length:  45\n",
      "The Score is : 0.9777777777777777\n",
      "\n",
      "Predicted output is : ['setosa']\n"
     ]
    }
   ],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "import random\n",
    "# Loading data\n",
    "data_iris = load_iris()\n",
    "# To get list of target names\n",
    "label_target = data_iris.target_names\n",
    "print()\n",
    "print(\"Sample Data from Iris Dataset\")\n",
    "print(\"*\"*30)\n",
    "# to display the sample data from the iris dataset\n",
    "for i in range(10):\n",
    "    rn = random.randint(0,120)\n",
    " \n",
    "print(data_iris.data[rn],\"===>\",label_target[data_iris.target[rn]])\n",
    "# Create feature and target arrays\n",
    "X = data_iris.data\n",
    "y = data_iris.target\n",
    "# Split into training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=1)\n",
    "print(\"The Training dataset length: \",len(X_train))\n",
    "print(\"The Testing dataset length: \",len(X_test))\n",
    "try:\n",
    "    nn = int(input(\"Enter number of neighbors :\"))\n",
    "    knn = KNeighborsClassifier(nn)\n",
    "    knn.fit(X_train, y_train)\n",
    "    # to display the score\n",
    "    print(\"The Score is :\",knn.score(X_test, y_test))\n",
    "    # To get test data from the user\n",
    "    test_data = input(\"Enter Test Data :\").split(\",\")\n",
    "    for i in range(len(test_data)):\n",
    "        test_data[i] = float(test_data[i])\n",
    "    print()\n",
    "    v = knn.predict([test_data])\n",
    "    print(\"Predicted output is :\",label_target[v])\n",
    "except:\n",
    "    print(\"Please supply valid input......\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>ChatGPT</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9111111111111111\n"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "# Load the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.3)\n",
    "\n",
    "# Create a k-NN classifier with k=3\n",
    "knn = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fit the classifier to the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Print the accuracy of the classifier on the testing data\n",
    "print(\"Accuracy:\", np.mean(y_pred == y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
